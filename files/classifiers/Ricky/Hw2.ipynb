{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Ri</font><font color=green>cky</font> <font color=Red>Var</font><font color=purple>gas</font><br>Homework 2<br>\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are importing all the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are importing the Data Set from this link and savind it into a DataFrame named df\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we make an Array to hold the labels we set this array to a variable named feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['sepal_length','sepal_width','petal_length','petal_width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have the variable feature_col we then tell the data frame that we want the columns with all of these labels, and we save this to variable X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we do the Same thing this time only getting the last column with label 'species' and saving that to variable y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this step we are splitting up the dataset that we provided in order to be able to get fidderent sets to test and train with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are telling the functions KNeighborClassifier that we want to choose the three closest values in order to make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "my_knn = KNeighborsClassifier(n_neighbors=k) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By using fit we are training the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we use the test values and save what the algorithm produces for each one in variable y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'virginica' 'setosa' 'setosa' 'virginica' 'versicolor'\n",
      " 'virginica' 'setosa' 'virginica' 'versicolor' 'virginica' 'versicolor'\n",
      " 'virginica' 'virginica' 'versicolor' 'versicolor' 'virginica'\n",
      " 'versicolor' 'versicolor' 'setosa' 'setosa' 'virginica' 'setosa' 'setosa'\n",
      " 'versicolor' 'versicolor' 'versicolor' 'virginica' 'setosa' 'versicolor'\n",
      " 'setosa' 'versicolor' 'setosa' 'setosa' 'versicolor' 'virginica'\n",
      " 'versicolor' 'virginica' 'versicolor' 'setosa' 'setosa' 'virginica'\n",
      " 'versicolor' 'versicolor' 'setosa' 'setosa' 'versicolor' 'setosa'\n",
      " 'setosa' 'versicolor' 'virginica' 'virginica' 'virginica' 'setosa'\n",
      " 'virginica' 'setosa' 'setosa' 'setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "y_predict = my_knn.predict(X_test)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have what the y alues actually are and what got predicted we want to see how accurate at it was guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  we now want to keep on guessing the same set but with different k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1,5,7,11,15,27,59]\n",
    "accuracyList= [0,0,0,0,0,0,0]\n",
    "counter = 0\n",
    "for x in numbers:\n",
    "    k=x\n",
    "    my_knn = KNeighborsClassifier(n_neighbors=k) \n",
    "    my_knn.fit(X_train, y_train)\n",
    "    y_predict = my_knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    accuracyList[counter] = accuracy\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We print out all of the accuracy's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n",
      "0.9833333333333333\n",
      "0.9666666666666667\n",
      "0.9666666666666667\n",
      "0.9333333333333333\n",
      "0.9166666666666666\n",
      "0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "for y in accuracyList:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No the accuracy does not always get better by increasing k, it is like a bell hits a peak then begins to go down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this piece of code what we do is that now we want to test the accuracy of only one feature at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyList = [0,0,0,0]\n",
    "features = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "counter = 0;\n",
    "for x in features:\n",
    "    feature_cols = [x]\n",
    "    X= df[feature_cols]\n",
    "    y = df['species']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=6)\n",
    "    k=3\n",
    "    my_knn= KNeighborsClassifier(n_neighbors=k) \n",
    "    my_knn.fit(X_train, y_train)\n",
    "    y_predict = my_knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    accuracyList[counter] = accuracy\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we print out the accruracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7166666666666667\n",
      "0.5666666666666667\n",
      "0.9333333333333333\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "for x in accuracyList:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best Feature with the highest accuracy seems to be petal-width .95\n",
    "#### The second Best feature is Petal-length .93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The same way that we wanted to see the accuracy of each one individually we know want to check them in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracyList = [0,0,0,0,0,0]\n",
    "counter = 0;\n",
    "feature_cols = ['sepal_length','sepal_width']\n",
    "X= df[feature_cols]\n",
    "y = df['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=6)\n",
    "k=3\n",
    "my_knn= KNeighborsClassifier(n_neighbors=k) \n",
    "my_knn.fit(X_train, y_train)\n",
    "y_predict = my_knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "accuracyList[counter] = accuracy\n",
    "counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here We are Doing Sepal_Length and Petal_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[feature_cols]\n",
    "feature_cols = ['sepal_length','petal_length']\n",
    "X= df[feature_cols]\n",
    "y = df['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=6)\n",
    "k=3\n",
    "my_knn= KNeighborsClassifier(n_neighbors=k) \n",
    "my_knn.fit(X_train, y_train)\n",
    "y_predict = my_knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "accuracyList[counter] = accuracy\n",
    "counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are doing Sepal_length and Petal_dwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[feature_cols]\n",
    "feature_cols = ['sepal_length','petal_width']\n",
    "X= df[feature_cols]\n",
    "y = df['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=6)\n",
    "k=3\n",
    "my_knn= KNeighborsClassifier(n_neighbors=k) \n",
    "my_knn.fit(X_train, y_train)\n",
    "y_predict = my_knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "accuracyList[counter] = accuracy\n",
    "counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we do Sepal_Width and Petal_Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[feature_cols]\n",
    "feature_cols = ['sepal_width','petal_length']\n",
    "X= df[feature_cols]\n",
    "y = df['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=6)\n",
    "k=3\n",
    "my_knn= KNeighborsClassifier(n_neighbors=k) \n",
    "my_knn.fit(X_train, y_train)\n",
    "y_predict = my_knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "accuracyList[counter] = accuracy\n",
    "counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we do sepal_width and petal_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[feature_cols]\n",
    "feature_cols = ['sepal_width','petal_width']\n",
    "X= df[feature_cols]\n",
    "y = df['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=6)\n",
    "k=3\n",
    "my_knn= KNeighborsClassifier(n_neighbors=k) \n",
    "my_knn.fit(X_train, y_train)\n",
    "y_predict = my_knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "accuracyList[counter] = accuracy\n",
    "counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And Finally in this block of code we do petal_length and petal_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[feature_cols]\n",
    "feature_cols = ['petal_length','petal_width']\n",
    "X= df[feature_cols]\n",
    "y = df['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=6)\n",
    "k=3\n",
    "my_knn= KNeighborsClassifier(n_neighbors=k) \n",
    "my_knn.fit(X_train, y_train)\n",
    "y_predict = my_knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "accuracyList[counter] = accuracy\n",
    "counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Printing the Accuracy of the Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8166666666666667\n",
      "0.9833333333333333\n",
      "0.95\n",
      "0.95\n",
      "0.95\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "for x in accuracyList:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The \"feature pair\" that provides the best accuracy is sepal_length and petal_length\n",
    "##### The \"feature pair\" actaully contains the second best feature petal length but the first best feature is not included. \n",
    "##### Because of this we can concude that the best two features together will not make the best \"feature pair\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the highest features would always make the best \"feature pair\" then this one would have came out to that they are but seeing as how they are not proves that the combo of the two best features does not always make the best feature pair, Sometimes their are no correlation between 2 features so putting them together might result in a bad accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
